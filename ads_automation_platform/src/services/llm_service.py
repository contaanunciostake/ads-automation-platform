"""
Servi√ßo de integra√ß√£o com Large Language Models (LLMs) para gera√ß√£o de an√∫ncios.
Este m√≥dulo fornece funcionalidades para gerar textos de an√∫ncios baseados em criativos e informa√ß√µes da empresa.
"""

import json
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime
import base64
import os
from abc import ABC, abstractmethod

class LLMProvider(ABC):
    """Classe base abstrata para provedores de LLM"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
    
    @abstractmethod
    def generate_ad_copy(self, prompt: str, max_tokens: int = 150) -> Dict[str, Any]:
        """Gerar texto de an√∫ncio baseado no prompt"""
        pass
    
    @abstractmethod
    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """Analisar imagem para extrair contexto"""
        pass

class OpenAIProvider(LLMProvider):
    """Provedor OpenAI (GPT-4)"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key)
        self.base_url = "https://api.openai.com/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def generate_ad_copy(self, prompt: str, max_tokens: int = 150) -> Dict[str, Any]:
        """Gerar texto de an√∫ncio usando GPT-4"""
        try:
            payload = {
                "model": "gpt-4",
                "messages": [
                    {
                        "role": "system",
                        "content": "Voc√™ √© um especialista em copywriting para an√∫ncios digitais. Crie textos persuasivos, claros e que gerem convers√µes."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": max_tokens,
                "temperature": 0.7
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "success": True,
                    "text": result["choices"][0]["message"]["content"].strip(),
                    "usage": result.get("usage", {}),
                    "model": "gpt-4"
                }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """Analisar imagem usando GPT-4 Vision"""
        try:
            # Codificar imagem em base64
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode("utf-8")
            
            payload = {
                "model": "gpt-4-vision-preview",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Analise esta imagem e descreva os elementos visuais, cores, estilo, produtos ou servi√ßos mostrados, e o sentimento geral transmitido. Esta an√°lise ser√° usada para criar textos de an√∫ncios."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 300
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "success": True,
                    "description": result["choices"][0]["message"]["content"].strip(),
                    "model": "gpt-4-vision"
                }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

class HuggingFaceProvider(LLMProvider):
    """Provedor Hugging Face"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key)
        self.base_url = "https://api-inference.huggingface.co/models"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def generate_ad_copy(self, prompt: str, max_tokens: int = 150) -> Dict[str, Any]:
        """Gerar texto de an√∫ncio usando modelo Hugging Face"""
        try:
            # Usando um modelo de gera√ß√£o de texto em portugu√™s
            model = "microsoft/DialoGPT-medium"
            
            payload = {
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": max_tokens,
                    "temperature": 0.7,
                    "do_sample": True
                }
            }
            
            response = requests.post(
                f"{self.base_url}/{model}",
                headers=self.headers,
                json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    generated_text = result[0].get("generated_text", "")
                    return {
                        "success": True,
                        "text": generated_text.replace(prompt, "").strip(),
                        "model": model
                    }
                else:
                    return {
                        "success": False,
                        "error": "Resposta inesperada da API"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """Analisar imagem usando modelo de vis√£o computacional"""
        try:
            # Usando um modelo de descri√ß√£o de imagens
            model = "Salesforce/blip-image-captioning-base"
            
            with open(image_path, "rb") as image_file:
                files = {"file": image_file}
                
                response = requests.post(
                    f"{self.base_url}/{model}",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    files=files
                )
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    return {
                        "success": True,
                        "description": result[0].get("generated_text", ""),
                        "model": model
                    }
                else:
                    return {
                        "success": False,
                        "error": "Resposta inesperada da API"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

class LocalLLMProvider(LLMProvider):
    """Provedor para LLM local (simulado para demonstra√ß√£o)"""
    
    def __init__(self, api_key: str = "local"):
        super().__init__(api_key)
    
    def generate_ad_copy(self, prompt: str, max_tokens: int = 150) -> Dict[str, Any]:
        """Simular gera√ß√£o de texto de an√∫ncio"""
        # Templates de exemplo baseados no prompt
        templates = [
            "Descubra {produto} - A solu√ß√£o perfeita para {beneficio}. Experimente agora e transforme sua experi√™ncia!",
            "üöÄ {produto} chegou para revolucionar! Aproveite nossa oferta especial e veja a diferen√ßa. Clique aqui!",
            "Voc√™ merece o melhor! {produto} oferece {beneficio} com qualidade incompar√°vel. Saiba mais!",
            "N√£o perca tempo! {produto} √© a escolha certa para quem busca {beneficio}. Garante j√° o seu!",
            "‚ú® Novidade: {produto}! A inova√ß√£o que voc√™ esperava para {beneficio}. Confira agora!"
        ]
        
        # Extrair informa√ß√µes do prompt
        import random
        template = random.choice(templates)
        
        # Simular an√°lise do prompt para extrair produto e benef√≠cio
        if "empresa" in prompt.lower():
            produto = "nossos produtos"
        else:
            produto = "nossa solu√ß√£o"
        
        if "economia" in prompt.lower():
            beneficio = "economizar tempo e dinheiro"
        elif "qualidade" in prompt.lower():
            beneficio = "m√°xima qualidade"
        else:
            beneficio = "resultados excepcionais"
        
        generated_text = template.format(produto=produto, beneficio=beneficio)
        
        return {
            "success": True,
            "text": generated_text,
            "model": "local-demo"
        }
    
    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """Simular an√°lise de imagem"""
        descriptions = [
            "Imagem profissional com cores vibrantes e design moderno. Transmite confian√ßa e inova√ß√£o.",
            "Visual clean e minimalista com foco no produto. Cores neutras que transmitem eleg√¢ncia.",
            "Imagem din√¢mica com elementos gr√°ficos chamativos. Ideal para p√∫blico jovem e moderno.",
            "Design corporativo com paleta de cores s√≥bria. Transmite profissionalismo e credibilidade.",
            "Visual criativo com elementos art√≠sticos. Desperta curiosidade e interesse do p√∫blico."
        ]
        
        import random
        description = random.choice(descriptions)
        
        return {
            "success": True,
            "description": description,
            "model": "local-vision-demo"
        }

class AdCopyGenerator:
    """Gerador de textos de an√∫ncios usando LLMs"""
    
    def __init__(self):
        self.providers = {}
        self.default_provider = None
    
    def add_provider(self, name: str, provider: LLMProvider, is_default: bool = False):
        """Adicionar um provedor de LLM"""
        self.providers[name] = provider
        if is_default or not self.default_provider:
            self.default_provider = name
    
    def generate_ad_variations(self, 
                             company_name: str, 
                             image_path: str = None, 
                             product_description: str = None,
                             target_audience: str = None,
                             platform: str = "facebook",
                             ad_objective: str = "conversions",
                             num_variations: int = 3,
                             provider_name: str = None) -> Dict[str, Any]:
        """Gerar m√∫ltiplas varia√ß√µes de texto de an√∫ncio"""
        
        if not self.providers:
            return {
                "success": False,
                "error": "Nenhum provedor de LLM configurado"
            }
        
        provider_name = provider_name or self.default_provider
        provider = self.providers.get(provider_name)
        
        if not provider:
            return {
                "success": False,
                "error": f"Provedor {provider_name} n√£o encontrado"
            }
        
        results = {
            "success": True,
            "company_name": company_name,
            "platform": platform,
            "objective": ad_objective,
            "variations": [],
            "image_analysis": None,
            "provider_used": provider_name
        }
        
        # Analisar imagem se fornecida
        if image_path and os.path.exists(image_path):
            image_analysis = provider.analyze_image(image_path)
            if image_analysis.get("success"):
                results["image_analysis"] = image_analysis["description"]
        
        # Construir prompt base
        prompt_parts = [
            f"Crie um texto de an√∫ncio para {platform} para a empresa \'{company_name}\'."
        ]
        
        if product_description:
            prompt_parts.append(f"Produto/Servi√ßo: {product_description}")
        
        if target_audience:
            prompt_parts.append(f"P√∫blico-alvo: {target_audience}")
        
        if results["image_analysis"]:
            prompt_parts.append(f"Contexto visual: {results["image_analysis"]}")
        
        prompt_parts.append(f"Objetivo da campanha: {ad_objective}")
        
        # Adicionar diretrizes espec√≠ficas da plataforma
        platform_guidelines = {
            "facebook": "O texto deve ser envolvente, usar emojis quando apropriado, e incluir uma call-to-action clara. M√°ximo 125 caracteres para o texto principal.",
            "google": "O texto deve ser direto, incluir palavras-chave relevantes, e ter um headline de at√© 30 caracteres e descri√ß√£o de at√© 90 caracteres.",
            "linkedin": "O texto deve ser profissional, focado em benef√≠cios de neg√≥cio, e adequado para um p√∫blico B2B.",
            "instagram": "O texto deve ser visual, usar hashtags relevantes, e ser adequado para um p√∫blico jovem e engajado."
        }
        
        prompt_parts.append(platform_guidelines.get(platform, "O texto deve ser persuasivo e adequado para a plataforma."))
        
        base_prompt = " ".join(prompt_parts)
        
        # Gerar varia√ß√µes
        for i in range(num_variations):
            variation_prompt = f"{base_prompt}\n\nVaria√ß√£o {i+1}: Crie um texto √∫nico e criativo."
            
            result = provider.generate_ad_copy(variation_prompt)
            
            if result.get("success"):
                # Processar o texto gerado para extrair componentes
                generated_text = result["text"]
                
                # Tentar extrair headline e descri√ß√£o
                lines = generated_text.split("\n")
                headline = lines[0].strip()
                description = "\n".join(lines[1:]).strip() if len(lines) > 1 else ""
                
                variation = {
                    "id": i + 1,
                    "headline": headline[:30] if platform == "google" else headline,
                    "description": description[:90] if platform == "google" else description,
                    "full_text": generated_text,
                    "platform": platform,
                    "character_count": len(generated_text),
                    "generated_at": datetime.now().isoformat()
                }
                
                results["variations"].append(variation)
            else:
                results["variations"].append({
                    "id": i + 1,
                    "error": result.get("error", "Erro na gera√ß√£o"),
                    "generated_at": datetime.now().isofor


